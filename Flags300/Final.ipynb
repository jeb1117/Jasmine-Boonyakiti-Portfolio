{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project name: Flag Database Fun Time\n",
    "\n",
    "### Team Leader: Cole Polychronis\n",
    "\n",
    "### Team Members: Merritt Ruthrauff, Kelsey Henrichsen, Jasmine Boonyakiti\n",
    "\n",
    "#### Data Description:\n",
    "\n",
    "Our original datasets has 194 records. We added an additional 13 countries formed after 1990 in order to test the accuracy of our model. Each record is described by these values:\n",
    "\n",
    "**Response Variableï¼š**\n",
    "* Religion of a Country      \n",
    "\n",
    "**Predictor Variables:**\n",
    "1. Name of country   \n",
    "2. Continent of country                  \n",
    "3. Quadrant of the world (relative to Greenwich and the Equator)   \n",
    "4. Area (in millions of square kilometers)                           \n",
    "5. Population (in millions) \n",
    "6. Language spoken  \n",
    "7. Number of vertical bars on flag              \n",
    "8. Number of horizontal stripes on flag         \n",
    "9. Number of colors on flag    \n",
    "10. Presence of red on flag\n",
    "11. Presence of green on flag\n",
    "12. Presence of blue on flag\n",
    "13. Presence of gold on flag\n",
    "14. Presence of white on flag\n",
    "15. Presence of black on flag\n",
    "16. Presence of orange on flag\n",
    "17. Main color on flag\n",
    "18. Number of circles on flag\n",
    "19. Number of crosses on flag\n",
    "20. Number of saltires (diagonal crosses) on flag\n",
    "21. Number of quartered sections\n",
    "22. Number of suns or stars on flag\n",
    "23. Presence of crescent on flag\n",
    "24. Presence of triangles on flag\n",
    "25. Presence of inanimate icon on flag\n",
    "26. Presence of animate icon on flag\n",
    "27. Presence of text on flag\n",
    "28. Color in top left of flag\n",
    "29. Color in bottom right of flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named charts",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-105023ed5c98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_plotlyjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBoxPlot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named charts"
     ]
    }
   ],
   "source": [
    "# load all necessary imported libraries\n",
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "import warnings\n",
    "from sklearn import tree as treeClass\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from bokeh.charts import BoxPlot, output_file, show\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.1: Load Data\n",
    "\n",
    "Because our data could not be downloaded from the UCI site, we created a very basic webcrawler to pull the dataset off of the UCI page. Since this gave us a list where some attributes were connected by \\n, we built a function to seperate these connected values. We then grouped these attributes together into the correct number of rows and converted them into a dataframe.\n",
    "\n",
    "## <span style=\"color:blue\"> Update for Step 3: Adding Data to Test our Model </span>\n",
    "\n",
    "In order to test the efficiency of the model that we developed for Step 2, we added 13 additional countries. These countries were founded/formed after the dataset we use was created (1990). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic HTML Scraper to peel data off of UCI webpage\n",
    "page = requests.get('https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data')\n",
    "tree = html.fromstring(page.text)\n",
    "info = tree.xpath('//text()')\n",
    "info = info[0].split(',')\n",
    "\n",
    "# method to untangle values connected by \\n (EX: 'green\\nAlbania')\n",
    "def untangle(arr):\n",
    "    untangled = []\n",
    "    for el in arr:\n",
    "        try: \n",
    "            ind = el.index('\\n')\n",
    "        except ValueError:\n",
    "            ind = -1\n",
    "        if ind == -1:\n",
    "            untangled.append(el)\n",
    "        else:\n",
    "            untangled.append(el[:ind])\n",
    "            untangled.append(el[ind+1:])\n",
    "    return untangled\n",
    "\n",
    "# group data into rows and convert to a Dataframe\n",
    "untangled = untangle(info)\n",
    "usable = [untangled[i:i + 30] for i in range(0, len(untangled), 30)]\n",
    "df = pd.DataFrame(usable)\n",
    "\n",
    "# remove last buffer row, which contains all None\n",
    "df = df[:-1]\n",
    "# convert all columns that should be numeric to ints (as they are currently all strings)\n",
    "indices = []\n",
    "for i in range(29):\n",
    "    if i != 0 and i != 17 and i != 28 and i != 29:\n",
    "        indices.append(i)\n",
    "df[indices] = df[indices].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.read_csv(\"./newCountries.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "superdf = pd.concat([df,df2])\n",
    "sdfCopy = superdf.copy(deep=True)\n",
    "superdf = pd.get_dummies(superdf, prefix=['continent', 'quadrant', 'language','mainColor','topLeftColor','bottomRightColor'], columns=[1, 2, 5, 17, 28, 29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "superdf.columns=['country','area (thousands of square of km)', 'population (millions)','religion','bars','stripes','numOfColors','red','green','blue','gold','white','black','orange','numOfCircles','numOfCrosses','numOfSaltires','numOfQuarters','numOfSunStars','crescent','triangle','icon','animate','text','inN.America','inS.America','inEurope','inAfrica','inAsia','inOceania','inNE','inSE','inSW','inNW','english','spanish','french','german','slavic','otherIndoEuropean','chinese','arabic','Japanese/Turkish/Finnish/Magyar','other',\n",
    "            'mainColor_black','mainColor_blue','mainColor_brown','mainColor_gold','mainColor_green','mainColor_orange','mainColor_red','mainColor_white','topLeftColor_black','topLeftColor_blue','topLeftColor_gold','topLeftColor_green','topLeftColor_orange','topLeftColor_red','topLeftColor_white','bottomRightColor_black',\n",
    "            'bottomRightColor_blue','bottomRightColor_brown',\n",
    "            'bottomRightColor_gold','bottomRightColor_green',\n",
    "            'bottomRightColor_orange','bottomRightColor_red',\n",
    "            'bottomRightColor_white','bottomRightColor_yellow']\n",
    "religions = {0: 'Catholic',1: 'Other Christian', 2: 'Muslim', 3: 'Buddhist', 4: 'Hindu', 5: 'Ethnic', 6: 'Marxist', 7: 'Other'}\n",
    "superdf[\"religion\"].replace(religions, inplace=True)\n",
    "superdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.2: Preprocessing\n",
    "This data is separated into each of the columns that represent the data we are going to analyze for each country. i.e. Area, population, religion, etc. In order to get the categorical variables to work with our dataset, we had to convert them using the .get_dummies to convert the data to use for the DecisionTreeClassifier. In order for the tree to make sense on the graphviz, there needed to be a modification of the column names.\n",
    "\n",
    "## <span style=\"color:blue\"> Update for Step 3: Realizing the Importance of Normalizing Data </span>\n",
    "After completing our first iteration through step 2, where our model derived almost 85% of its predictive power from the Population of the country, we realized the importance of normalizing numerical data in our dataset. In order to normalize the data, we took the top 4% of data in each numerical category and converted it to a null value. We then replaced these null values with the mean of each column. The graphs of the data before and after removing outliers are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=[superdf['area (thousands of square of km)'].quantile(0.96), superdf['population (millions)'].quantile(0.96), superdf['numOfColors'].quantile(0.96)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kde_plot(x):   \n",
    "    kde = gaussian_kde(x)\n",
    "    positions = np.linspace(x.min(), x.max())\n",
    "    smoothed = kde(positions)\n",
    "    plt.plot(positions, smoothed)\n",
    "    \n",
    "def kde_values(x):   \n",
    "    kde = gaussian_kde(x)\n",
    "    positions = np.linspace(x.min(), x.max())\n",
    "    smoothed = kde(positions)\n",
    "    return positions, smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=superdf['area (thousands of square of km)']\n",
    "x=x.dropna()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,5)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "positions, smoothed = kde_values(x)\n",
    "ax1.plot(positions, smoothed)\n",
    "ax1.set_title('Area: All Data')\n",
    "positions, smoothed = kde_values(x[x<2777])\n",
    "ax2.plot(positions, smoothed)\n",
    "ax2.set_title('Area: Data after deleting outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=superdf['population (millions)']\n",
    "x=x.dropna()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,5)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "positions, smoothed = kde_values(x)\n",
    "ax1.plot(positions, smoothed)\n",
    "ax1.set_title('Population: All Data')\n",
    "positions, smoothed = kde_values(x[x<85.68])\n",
    "ax2.plot(positions, smoothed)\n",
    "ax2.set_title('Population: Data after deleting outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=superdf['numOfColors']\n",
    "x=x.dropna()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,5)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "positions, smoothed = kde_values(x)\n",
    "ax1.plot(positions, smoothed)\n",
    "ax1.set_title('Number of Colors on Flag: All Data')\n",
    "positions, smoothed = kde_values(x[x<6.28])\n",
    "ax2.plot(positions, smoothed)\n",
    "ax2.set_title('Number of Colors on Flag: Data after deleting outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "superdf['area (thousands of square of km)']=superdf['area (thousands of square of km)'].map(lambda x: None if x>m[0] else x)\n",
    "superdf['population (millions)']=superdf['population (millions)'].map(lambda x: None if x>m[1] else x)\n",
    "superdf['numOfColors']=superdf['numOfColors'].map(lambda x: None if x>m[2] else x)\n",
    "superdf = superdf.fillna(superdf.mean())\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "superdf['area (thousands of square of km)'] = preprocessing.StandardScaler().fit_transform(superdf['area (thousands of square of km)'])\n",
    "superdf['population (millions)'] = preprocessing.StandardScaler().fit_transform(superdf['population (millions)'])\n",
    "superdf['numOfColors'] = preprocessing.StandardScaler().fit_transform(superdf['numOfColors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Update for Step 3: Creating Test Data </span>\n",
    "In order to test the efficacy of our models developed for step 2, we create data that will be used specifically for testing our model (and not for training it). Based on our observations that we will discuss in greater detail for Step 3 below, we create 2 kernels for training and testing. For the first kernel, we use all of the data from the original UCI dataset as training data and the data that we created from countries formed after 1990 as the testing data. For the second kernel, we use a combination of a portion of the UCI dataset and all of our created data as our training data, and the remaining (unused) portion of the UCI dataset as our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframe to train models on\n",
    "df = superdf[0:194]\n",
    "# dataframe to test models on (new data)\n",
    "testdf = superdf[195:-1]\n",
    "# dataframes to show sensitivity to timeframe of our model\n",
    "df2 = superdf[12:-1]\n",
    "testdf2 = superdf[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df = df.drop(['country','religion'], axis=1)\n",
    "target_df = df['religion']\n",
    "\n",
    "data = data_df.as_matrix()\n",
    "target = target_df.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.3: Modeling using Decision Tree\n",
    "For this part, we had to put the data that we had created above into the Decision Tree Classifier to finally see the output of the data. Instead of the data being used as whole numbers, the data was converted to percentages to show the importance of each category. With the output given, the population data is the most important feauture when comparing the religion of a country to the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Decision Tree Classifier and determine which features are most important\n",
    "clf = treeClass.DecisionTreeClassifier()\n",
    "clf.fit(data,target)\n",
    "\n",
    "y_pred = clf.predict(data)\n",
    "classif_rate = np.mean(y_pred.ravel() == target.ravel()) * 100\n",
    "print(\"classif_rate for %s : %f \" % ('RandomForestClassifier', classif_rate))\n",
    "print clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.4: Visualization\n",
    "The final step was to import the graphviz package and use it to take the information and make a tree to display the. The information that is displayed is the decision tree from above (clf), the table that holds the information (feature_names), and the religion from each country (class_names). With the categorical variables such as the inS.America, the value is <= 0.5 which means the value is 0 or not true in this case. When looking at any of the data that has a value of > 0 which makes the value true. \n",
    "\n",
    "***Note: The Decision Tree produced by this model is large, so you may have to scroll around some to start seeing the branches of the tree.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize the decision tree\n",
    "import graphviz\n",
    "dot_data = treeClass.export_graphviz(clf, out_file=None,\n",
    "#                                max_depth=5,\n",
    "                               filled=True, rounded=True,\n",
    "                               feature_names=df.columns,\n",
    "                               class_names=['Catholic','Other Christian', 'Muslim', 'Buddhist', 'Hindu', 'Ethnic', 'Marxist', 'Other']) \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.1: Model and Parameter Selection\n",
    "In order to find the best model for our data, and the best parameters to use with that model, we use Grid Search on our choice of five models: a Decision Tree, a Random Forest, a Gradient Boosting Model, a Support Vector Machine, and a Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(), SVC(), MLPClassifier()]\n",
    "tuned_parameters = [{'max_depth': [None,10,20], 'criterion': ['gini','entropy']}, # parameters for decision tree\n",
    "                   {'n_estimators':[10,20,30,40], 'max_depth':[None, 10, 20]}, # parameters for random forest\n",
    "                   {'n_estimators':[10,20,30,40], 'max_depth':[None, 10, 20]}, # parameters for gradient boost\n",
    "                   {'decision_function_shape':['ovo'], 'degree':[1,2,3,4,5]}, # parameters for support vector machine\n",
    "                   {'solver': ['lbfgs', 'sgd', 'adam'], 'max_iter': [200, 300, 400]} # parameters for neural network\n",
    "                   ]\n",
    "for model, tuned_parameter in zip(models, tuned_parameters):\n",
    "    classify = GridSearchCV(model,tuned_parameter,cv=4,verbose=1)\n",
    "    classify.fit(data,target)\n",
    "    print classify.best_params_\n",
    "    print classify.best_score_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.2: Model Evaluation\n",
    "After we determined the Random Forest Classifier with a max_depth of 20 and 30 estimators to be our best model, we move on to testing its accuracy in predicting the religion of a country. We use K-Fold Cross-Validation to test on average, how accurately our model is able to predict the religion of a country using 4/5 of the data to train on. We found that our model has an average accuracy of 70% +/- 8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classify = RandomForestClassifier(n_estimators = 40, max_depth = None)\n",
    "classify.fit(data,target)\n",
    "\n",
    "y_pred = classify.predict(data)\n",
    "classif_rate = np.mean(np.equal(y_pred.ravel(), target.ravel())) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec = RandomForestClassifier(n_estimators = 40, max_depth = None, criterion='gini')\n",
    "scores = cross_val_score(dec, data, target, cv=4)\n",
    "print(\"Model Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization using Matplotlib\n",
    "## <span style=\"color:blue\"> Update for Step 3: More Reasonable Feature Importances </span>\n",
    "\n",
    "Here, we use the Matploblib Library to visualize which features are most important to our model in determining the religion of a country. In stark contrast to our original graph of these feature importances, which suggested that the population of a country had almost an 85% weight in determining the religion of a country, we now see a more reasonable spread. While Population is still clearly an important according to our graph below, we can see that the area of the country is almost equally important. We can also see that things that should be slighly indicative of religion, such as language, the continent that the country resides in, and even some flag features such as presence of suns, stars, and crosses (all of which are pretty religously symbolic), begin to play a role in predicting religion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features= data_df.columns.values\n",
    "value = classify.feature_importances_\n",
    "ind=sorted(range(len(value)),reverse=False,key=lambda k: value[k])\n",
    "features=features[ind]\n",
    "value=sorted(value,reverse=False)\n",
    "ind=np.array(range(len(features)))\n",
    "plt.rcParams['figure.figsize'] = (9,15)\n",
    "plt.barh(bottom=ind,height=0.5,width=value,color='r')\n",
    "plt.yticks(ind,features)\n",
    "plt.xlabel('Weights')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualization using Plotly\n",
    "## <span style=\"color:blue\"> Update for Step 3: Exploring Area and Population </span>\n",
    "\n",
    "In light of the new set of feature importances that we visualized above, we believed it would be beneficial to take a closer look at Area and Population. To do this, we use the Plotly Library and Platform to visualize the Scatterplot of Area vs. Population. The benefit of having this plot be interactive is that we can explore different clusters of data. For example, clicking and dragging to view the window of Area between -1 and 4, and Population between -1 and 4, allows us to see that a significant number of Muslim countries can be found on the \"outer band\", which suggests that Muslim countries are larger in area and tend to be populated by more people. Likewise, clicking and dragging to view the window of Area between -1 and 1, and Population between -1 and 0, we can see that a large number of Ethnically religious countries can be found in the innermost \"band\" or cluster, which indicates that Ethnic countries tend to be smaller in area and populated by less people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = {\n",
    "    'data': [\n",
    "        {\n",
    "            'x': df[df['religion']==religion]['population (millions)'],\n",
    "            'y': df[df['religion']==religion]['area (thousands of square of km)'],\n",
    "            'name': religion, 'mode': 'markers',\n",
    "        } for religion in ['Catholic','Other Christian', 'Muslim', 'Buddhist', 'Hindu', 'Ethnic', 'Marxist', 'Other']\n",
    "    ],\n",
    "    'layout': {\n",
    "        'title': 'Area vs. Population grouped by Religion',\n",
    "        'xaxis': {'title': 'Population (normalized)'},\n",
    "        'yaxis': {'title': \"Area (normalized)\"}\n",
    "    }\n",
    "}\n",
    "py.iplot(fig, filename='Area vs Population grouped by Religion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations using Bokeh\n",
    "## <span style=\"color:blue\"> Update for Step 3: Taking a Closer Look at Area and Population </span>\n",
    "Considering that they were our most important features, we felt that it was warranted to spend a little more time exploring the area and population features of our dataset. To do so, we used the Bokeh Library to visualize the boxplots of both area and population. Using side-by-side boxplots specifically is helpful because it allows us to simulatenously compare spread and center of each one of the religous groups in terms of area and religion. \n",
    "\n",
    "In regards to area, we can see that the \"Other\" and \"Other Christian\" categories are the most tightly grouped, which indicates that prediction of these religions might be more accurate. Compare this with the Muslim and Hindu groups, which are both significantly spread out, especially for the upper quantiles. This might indicate that predictions for these religions are slightly less accurate. We can also see that by far, the \"Other Chrisitian\" group has the largest number of outliers, also possibly decreasing accuracy for these predictions.\n",
    "\n",
    "In regards to population, we can see that there is significantly less difference in the spread between groups, with Buddhist, Muslim, and \"Other\" countries being slightly more spread out than the others, but not by much. However, we can see that the Muslim and \"Other Christian\" countries have significantly more outliers than the rest of the groups, once again raising the concern that predicition of these religions might be slightly less accurate.\n",
    "\n",
    "***Note: These visualizations are rendered on different web pages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "box = BoxPlot(df, values='population (millions)', label='religion', color='religion', title='Distribution of Population by Religion', width=600)\n",
    "\n",
    "output_file('box.html')\n",
    "show(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "box = BoxPlot(df, values='area (thousands of square of km)', label='religion', color='religion', title='Distribution of Population by Religion', width=600)\n",
    "\n",
    "output_file('box.html')\n",
    "show(box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.1: Predicting on our Generated Data\n",
    "Below, we use our optimal model of a Random Forest Classifier to predict the religion of the data we generated based on countries that were formed after our dataset was created (in 1990). As can be seen from the first of our prediction accuracies below, when we train on the UCI data and test on our generated data, we have less accuracy than a random coin flip, which means that our model is meaningless. More interesting, however, is the second of our prediction accuracies, where we train on a combination of a portion of the UCI dataset and all of our generated data and test on the remaining (unused) portion of the UCI dataset, where our accuracy is close to 90%. This seems to suggest that while our model is terrible for predicting religion for moden day countries, it is a powerful model for predicting religion of countries pre-1990. We explore this graphically below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newData = testdf.drop(['country','religion'], axis=1).as_matrix()\n",
    "newTarget = testdf['religion'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = RandomForestClassifier(n_estimators = 40, max_depth = None)\n",
    "predictor.fit(data,target)\n",
    "\n",
    "yhat=predictor.predict(newData)\n",
    "print 'Prediction Accuracy for Kernel 1 Data (Testing on our generated data)'\n",
    "print accuracy_score(newTarget,yhat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = df2.drop(['country','religion'], axis=1).as_matrix()\n",
    "target2 = df2['religion']\n",
    "\n",
    "newData2 = testdf2.drop(['country','religion'], axis=1).as_matrix()\n",
    "newTarget2 = testdf2['religion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor2 = RandomForestClassifier(n_estimators = 40, max_depth = None)\n",
    "predictor2.fit(data2,target2)\n",
    "\n",
    "yhat2=predictor2.predict(newData2)\n",
    "print 'Prediction Accuracy for Kernel 2 Data (Testing on our unused portion of UCI data)'\n",
    "print accuracy_score(newTarget2,yhat2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization using Seaborn\n",
    "## <span style=\"color:blue\"> Update for Step 3: Analyzing Accuracy of Our Model on Different Datasets </span>\n",
    "Here, we use the Seaborn Library to visualize the confusion matrices of our model when training it and testing it on Kernel 1 data versus Kernel 2 data. In essence, the confusion matrices below allow us to see how well our model performs by comparing the religion preddicted by our model against the actual religion of a country. More importanly, however, is the fact that confusion matrices can offer some insight into how specifically our model predicts/is failing to predict religion. For example, the confusion matrix on the left, which corresponds to our Kernel 1 data, demonstrates that our model was only able to accurately predict the ethnic countries well. Of the 8 countries our model incorrectly predicted, it predicted the religion to be Muslim for 4 of them. This could tie back to our concern address earlier in the Bokeh plots, which seemed to indicate that there was a lot of spread in terms of the data for Muslim countries in terms of Area and Population (our two most important features). This could be indicative that our model is overfitting. However, when we consider the confusion matrix on the right, which is trained on data according to Kernel 2, it seems to indicate that perhaps overfitting is not the problem and that instead, our model is fairly accurate for predicting the religion of countries that existed during the 1990's, but is less accurate for the countries that formed post-1990."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm1 = confusion_matrix(newTarget, yhat)\n",
    "df_cm1 = pd.DataFrame(cm1, index = [i for i in ['Catholic','Other Christian', 'Muslim', 'Buddhist', 'Ethnic', 'Marxist']],\n",
    "                  columns = [i for i in ['Catholic','Other Christian', 'Muslim', 'Buddhist', 'Ethnic', 'Marxist']])\n",
    "\n",
    "cm2 = confusion_matrix(newTarget2, yhat2)\n",
    "df_cm2 = pd.DataFrame(cm2, index = [i for i in ['Catholic','Other Christian', 'Muslim', 'Ethnic', 'Marxist']],\n",
    "                  columns = [i for i in ['Catholic','Other Christian', 'Muslim', 'Ethnic', 'Marxist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,5)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "sn.heatmap(df_cm1, annot=True, ax=ax1).set_title('Confusion Matrix for Predictions of New Countries')\n",
    "sn.heatmap(df_cm2, annot=True, ax=ax2).set_title('Confusion Matrix for Predictions of Countries from Time of Dataset (1990)')\n",
    "\n",
    "fig.tight_layout()\n",
    "ax1.set_xlabel(\"Predicted Religion\")\n",
    "ax1.set_ylabel(\"Actual Religion\")\n",
    "ax2.set_xlabel(\"Predicted Religion\")\n",
    "ax2.set_ylabel(\"Actual Religion\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
